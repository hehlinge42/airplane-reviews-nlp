{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/rwalk/gsdmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "from gsdmm.gsdmm import MovieGroupProcess\n",
    "\n",
    "from src.text_preprocessor import TextPreprocessor\n",
    "from src.embeddor import Embeddor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "DATA1 = \"seatguru_python_scraping.csv\"\n",
    "DATA2 = \"skytrax_scraping_2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(os.path.join(DATA_FOLDER, DATA1))\n",
    "df2 = pd.read_csv(os.path.join(DATA_FOLDER, DATA2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_small = df2.copy().iloc[:5000, :]\n",
    "preprocessor = TextPreprocessor(df2_small, column_to_clean='body')\n",
    "preprocessor.transform(n_grams=False, remove_stopwords=True)\n",
    "corpus = preprocessor.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus)\n",
    "embeddor.transform(vec_method=\"word2vec\", how=\"PCA\", n=3)\n",
    "word2vec_embed = embeddor.description_embedding\n",
    "word2vec_model = embeddor.model\n",
    "word2vec_embed['corpus'] = corpus\n",
    "word2vec_embed['rating'] = df2_small['rating']\n",
    "word2vec_embed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_small[\"corpus\"] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary\n",
    "tokens = df2_small.corpus\n",
    "dictionary = gensim.corpora.Dictionary(tokens)\n",
    "dictionary.filter_extremes(no_below=0.05, no_above=0.9)\n",
    "corpus_lda = [dictionary.doc2bow(tok) for tok in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel = gensim.models.ldamodel.LdaModel(corpus=corpus_lda,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=42,\n",
    "                                           alpha=0.1,\n",
    "                                           eta=0.1,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, topic in ldaModel.show_topics(formatted=True, num_topics=10, num_words=20):\n",
    "    print(str(i)+\": \"+ topic+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CoherenceModel(model=ldaModel, corpus=corpus, texts=tokens ,coherence=\"c_v\")\n",
    "cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldaModel, corpus_lda, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_small['nb_token'] = list(map(len, df2_small['corpus']))\n",
    "docs = df2_small.corpus.to_list()\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_topic = 10\n",
    "alpha = 0.1\n",
    "beta = 0.1\n",
    "\n",
    "mgpModel = MovieGroupProcess(K=nb_topic, alpha=alpha, beta=beta, n_iters=20)\n",
    "mgpModelFit = mgpModel.fit(tokens, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topWordsPerTopic(clusterDistrib, topIndex, nbWord):\n",
    "    for index in topIndex:\n",
    "        clusterWord = clusterDistrib[index]\n",
    "        sortedCluster = sorted(clusterWord.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        clusterTopWords = sortedCluster[:nbWord]\n",
    "        print(f\"Cluster {index} : {clusterTopWords}\")\n",
    "        print('*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docCount = np.array(mgpModel.cluster_doc_count)\n",
    "print('Number of documents per topic :', docCount)\n",
    "print('*'*20)\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "topIndex = docCount.argsort()[::-1]\n",
    "print('Most important clusters (by number of docs inside):', topIndex)\n",
    "print('*'*20)\n",
    "# Show the top 30 words in term frequency for each cluster \n",
    "topWordsPerTopic(mgpModel.cluster_word_distribution, topIndex, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6972ee2bd1b4509a80cf34a71ca27c907c02bd1bee408bb4a0ddede37fe3d1b4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('11_hack': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
