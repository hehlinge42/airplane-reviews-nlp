{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/rwalk/gsdmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "from gsdmm.gsdmm import MovieGroupProcess\n",
    "\n",
    "from src.text_preprocessor import TextPreprocessor\n",
    "from src.embeddor import Embeddor\n",
    "from src.utils.plotting_utils import tf_idf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data\"\n",
    "DATA1 = \"seatguru_python_scraping.csv\"\n",
    "DATA2 = \"skytrax_scraping_2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(os.path.join(DATA_FOLDER, DATA1))\n",
    "df2 = pd.read_csv(os.path.join(DATA_FOLDER, DATA2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='rating', data=df2)\n",
    "plt.title('Number of reviews per rating')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel(' ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin(rating):\n",
    "    if rating <= 3:\n",
    "        return \"Bad\"\n",
    "    elif rating > 3 and rating < 8:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['bin'] = df2['rating'].apply(bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='bin', data=df2)\n",
    "plt.title('Number of reviews per bin')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel(' ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series annalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3.date = pd.to_datetime(df3.date)\n",
    "df3 = df3.loc[df3.airline == \"american-airlines\"]\n",
    "df3['month'] = df3.date.dt.month\n",
    "df3['year'] = df3.date.dt.year\n",
    "rat_by_month = df3.dropna(subset=[\"rating\"]).groupby([\"month\", \"year\"]).agg({'rating':'mean'}).sort_index(level=[1, 0])\n",
    "rat_by_month.index = rat_by_month.index.get_level_values(0).astype(str) + '-' + rat_by_month.index.get_level_values(1).astype(str)\n",
    "#rat_by_month['date'] = rat_by_month.month.astype(str) + '-' + rat_by_month.year.astype(str)\n",
    "rat_by_month.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df2.copy()\n",
    "df4.date = pd.to_datetime(df4.date)\n",
    "df4 = df4.loc[df4.airline == \"american-airlines\"]\n",
    "df4['month'] = df4.date.dt.month\n",
    "df4['year'] = df4.date.dt.year\n",
    "rat_by_month = df4.dropna(subset=[\"rating\"]).groupby([\"month\", \"year\"]).agg({'rating':'count'}).sort_index(level=[1, 0])\n",
    "rat_by_month.index = rat_by_month.index.get_level_values(0).astype(str) + '-' + rat_by_month.index.get_level_values(1).astype(str)\n",
    "#rat_by_month['date'] = rat_by_month.month.astype(str) + '-' + rat_by_month.year.astype(str)\n",
    "rat_by_month.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = df2.loc[df2.bin == \"Good\"]\n",
    "preprocessor = TextPreprocessor(df_good, column_to_clean='body')\n",
    "preprocessor.transform(n_grams=False, remove_stopwords=True)\n",
    "corpus_good = preprocessor.corpus\n",
    "\n",
    "df_bad = df2.loc[df2.bin == \"Bad\"]\n",
    "preprocessor = TextPreprocessor(df_bad, column_to_clean='body')\n",
    "preprocessor.transform(n_grams=False, remove_stopwords=True)\n",
    "corpus_bad = preprocessor.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = tf_idf(corpus_good, wordcloud=True, rating=\"Good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = tf_idf(corpus_bad, wordcloud=True, rating=\"Bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_small = df2.copy().iloc[:5000, :]\n",
    "preprocessor = TextPreprocessor(df2_small, column_to_clean='body')\n",
    "preprocessor.transform(n_grams=False, remove_stopwords=True)\n",
    "corpus = preprocessor.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus)\n",
    "embeddor.transform(vec_method=\"word2vec\", how=\"PCA\", n=3)\n",
    "lsi = embeddor.description_embedding\n",
    "word2vec_model = embeddor.model\n",
    "lsi['corpus'] = corpus\n",
    "lsi['rating'] = df2_small['rating']\n",
    "lsi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    rat_list = []\n",
    "    lsi[f'Dimension_{i+1}'] = np.abs(lsi[f'Dimension_{i+1}'])\n",
    "    top_words = lsi.sort_values(f'Dimension_{i+1}', ascending=False).index[:5]\n",
    "    print((f\"Top reviews for topic {i} are : \"))\n",
    "    print(lsi.corpus.apply(lambda x: x[2:]).iloc[top_words])\n",
    "    print(f\"Average rating for topic {i} are : \")\n",
    "    ratings = df2_small.rating.tolist()\n",
    "    for ind in list(top_words):\n",
    "        rat_list.append(ratings[ind])\n",
    "    print(np.mean(rat_list))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "colors = ['red', 'red', 'red', 'yellow', 'yellow', 'yellow', 'yellow', 'green', 'green', 'green']\n",
    "\n",
    "for val in lsi['rating'].dropna().astype(int).unique():\n",
    "    topic_1 = np.abs(lsi[lsi['rating']==val]['Dimension_1'].values)\n",
    "    topic_2 = np.abs(lsi[lsi['rating']==val]['Dimension_3'].values)\n",
    "    color = colors[val-1]\n",
    "    ax.scatter(topic_1, topic_2, alpha=0.7, label=val, color=color)\n",
    "    \n",
    "ax.set_xlabel('First Topic')\n",
    "ax.set_ylabel('Second Topic')\n",
    "ax.axvline(linewidth=0.5)\n",
    "ax.axhline(linewidth=0.5)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_small[\"corpus\"] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary\n",
    "tokens = df2_small.corpus\n",
    "dictionary = gensim.corpora.Dictionary(tokens)\n",
    "dictionary.filter_extremes(no_below=0.05, no_above=0.9)\n",
    "corpus_lda = [dictionary.doc2bow(tok) for tok in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel = gensim.models.ldamodel.LdaModel(corpus=corpus_lda,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=42,\n",
    "                                           alpha=0.1,\n",
    "                                           eta=0.1,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, topic in ldaModel.show_topics(formatted=True, num_topics=10, num_words=20):\n",
    "    print(str(i)+\": \"+ topic+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CoherenceModel(model=ldaModel, corpus=corpus, texts=tokens ,coherence=\"c_v\")\n",
    "cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(ldaModel, corpus_lda, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_small['nb_token'] = list(map(len, df2_small['corpus']))\n",
    "docs = df2_small.corpus.to_list()\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_topic = 10\n",
    "alpha = 0.1\n",
    "beta = 0.1\n",
    "\n",
    "mgpModel = MovieGroupProcess(K=nb_topic, alpha=alpha, beta=beta, n_iters=20)\n",
    "mgpModelFit = mgpModel.fit(tokens, n_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topWordsPerTopic(clusterDistrib, topIndex, nbWord):\n",
    "    for index in topIndex:\n",
    "        clusterWord = clusterDistrib[index]\n",
    "        sortedCluster = sorted(clusterWord.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        clusterTopWords = sortedCluster[:nbWord]\n",
    "        print(f\"Cluster {index} : {clusterTopWords}\")\n",
    "        print('*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docCount = np.array(mgpModel.cluster_doc_count)\n",
    "print('Number of documents per topic :', docCount)\n",
    "print('*'*20)\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "topIndex = docCount.argsort()[::-1]\n",
    "print('Most important clusters (by number of docs inside):', topIndex)\n",
    "print('*'*20)\n",
    "# Show the top 30 words in term frequency for each cluster \n",
    "topWordsPerTopic(mgpModel.cluster_word_distribution, topIndex, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6972ee2bd1b4509a80cf34a71ca27c907c02bd1bee408bb4a0ddede37fe3d1b4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('11_hack': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
